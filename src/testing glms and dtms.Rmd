---
title: "Creating DTMs and fitting GLMs"
author: "Daniel Krasnov"
date: "2023-03-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Libraries, echo=FALSE}
library(tm)
library(MLmetrics)
library(glmnet)
library(qdapRegex)
```


```{r}
data_1to2 <- read.csv("C:\\Users\\danie\\OneDrive\\Desktop\\Data-410-Sarcasm-Detection\\src\\data_1to2_vaxxhappenend.csv",header=TRUE)
colnames(data_1to2)
data_clean <- data_1to2[,c("Body","Sarcastic")]
doc_id <- rownames(data_clean)
data_clean$doc_id <- doc_id
y <- data_clean$Sarcastic
data_clean <- data_clean[,c("doc_id","Body")]
colnames(data_clean)[2] <- "text"
data_clean
```

# TF-IDF

We are interested in dimensionality reduction. To do this we will cut out terms based on the percentiles of TF-IDFs in the full model.

```{r Make Corpus}
data_clean$text <- rm_non_words(data_clean$text)
ds <- DataframeSource(data_clean)
corpus <- Corpus(ds)
inspect(corpus[1:5])
```

```{r Clean corpus}
# Clean the Corpus

# Remove punctuation
corpus <- tm_map(corpus, content_transformer(removePunctuation))
# Send everything to lower case
corpus <- tm_map(corpus, content_transformer(tolower))
# Remove stopwords
corpus <- tm_map(corpus, content_transformer(removeWords), 
          stopwords("english"))
# Remove whitespace
corpus <- tm_map(corpus, stripWhitespace)
# Remove numbers
corpus <- tm_map(corpus, content_transformer(removeNumbers))
# Stemming
corpus <- tm_map(corpus, stemDocument)

inspect(corpus[1:5])
```

```{r create DTM}
# Create DTM object
dtm <- DocumentTermMatrix(corpus)
# Weight TF-IDF
tfidf_dtm <- weightTfIdf(dtm)
inspect(tfidf_dtm[,1:3])
```

```{r Find min AIC, cache=TRUE}
# Get quantile
tfidf_mat <- as.matrix(tfidf_dtm)

tfidf_vec <- as.vector(tfidf_mat)

tfidf_vec <- tfidf_vec[tfidf_vec > 0] 

quants <- quantile(tfidf_vec, probs = seq(0.1,0.9,0.05))

models_aic <- list()

iter <- 0
for (quant in quants) {
  iter <- iter + 1
  print(iter)
  # Filter DTM
  tfidf_dtm_r <- tfidf_dtm[,tfidf_dtm$v > quant]

  # Construct dataframe for fitting
  x_data <- as.data.frame(as.matrix(tfidf_dtm_r))
  data <- cbind(y,data_clean)
  y_data <- as.data.frame(subset(data, doc_id %in% tfidf_dtm_r$dimnames$Docs)$y)
  data <- cbind(y_data,x_data)
  colnames(data)[1] <- "y"
  
  # Fit model
  glm.out <- glm(y~., family = binomial, data)
  models_aic <- append(models_aic, glm.out$aic)
}
```

```{r Print min AIC}
print(which.min(models_aic))
```
```{r}
print(quants[17])
```


So the min AIC is the 90 percentile which is a filter of the DTM at 1.217297. We now know a good quantile to threshold any DTM we choose to use (is this an okay thing to do). Now we can do a validation approach to get test metrics.

```{r}
 # Filter DTM
  tfidf_dtm_r <- tfidf_dtm[,tfidf_dtm$v > 1.217297]

  # Construct dataframe for fitting
  x_data <- as.data.frame(as.matrix(tfidf_dtm_r))
  # data <- cbind(y,data)
  # y_data <- as.data.frame(subset(data_clean, doc_id %in% tfidf_dtm_r$dimnames$Docs)$y)
  data <- cbind(y,x_data)
  colnames(data)[1] <- "y"
  
set.seed(87460945)
train_idx <- sample(1:nrow(data),floor(.6*(nrow(data))))
test_idx <- setdiff(1:nrow(data),train_idx)
  
glm.out <- glm(y~., family = binomial, data[train_idx,])
summary(glm.out)
```

Get training metrics
```{r Fit model}
predict.out <- predict(glm.out, type="response")

predict.out[which(predict.out >= 0.5)] <- 1

predict.out[which(predict.out < 0.5)] <- 0

guess <- data.frame(predict.out)

output <- cbind(guess,y[train_idx])
colnames(output)[2] <- "truth"
output
```

Now we can investigate our metrics

```{r}
library(MLmetrics)
cm <- ConfusionMatrix(output$predict.out, output$truth)
print(cm)

y_true <- output$truth
y_pred <- output$predict.out
print("Specificity:")
Specificity(y_true, y_pred, positive = 1)

print("Recall:")
Recall(y_true, y_pred, positive = 1)

print("Precision:")
Precision(y_true, y_pred, positive = 1)

print("Accuracy:")
Accuracy(y_pred, y_true)

print("F1_Score:")
F1_Score(y_true, y_pred, positive = 1)
```

Now we do test metrics
```{r Split data intro train/test}
predict.out <- predict(glm.out, newdata = as.data.frame(as.matrix(tfidf_dtm[test_idx,])) ,type="response")

predict.out[which(predict.out >= 0.5)] <- 1

predict.out[which(predict.out < 0.5)] <- 0

guess <- data.frame(predict.out)

output <- cbind(guess,y[test_idx])
colnames(output)[2] <- "truth"
output
```


```{r}
library(MLmetrics)
cm <- ConfusionMatrix(output$predict.out, output$truth)
print(cm)

y_true <- output$truth
y_pred <- output$predict.out
print("Specificity:")
Specificity(y_true, y_pred, positive = 1)

print("Recall:")
Recall(y_true, y_pred, positive = 1)

print("Precision:")
Precision(y_true, y_pred, positive = 1)

print("Accuracy:")
Accuracy(y_pred, y_true)

print("F1_Score:")
F1_Score(y_true, y_pred, positive = 1)
```


# Try on raw data
```{r}
full_data <- read.csv("../data/vaxxhappened.csv")
full_data$doc_id <- rownames(full_data) 
data_clean <- full_data[,c("Body","Sarcastic")]
doc_id <- rownames(data_clean)
data_clean$doc_id <- doc_id
y <- data_clean$Sarcastic
data_clean <- data_clean[,c("doc_id","Body")]
colnames(data_clean)[2] <- "text"
data_clean
```

```{r}
data_clean$text <- rm_non_words(data_clean$text)
ds <- DataframeSource(data_clean)
corpus <- Corpus(ds)
inspect(corpus[1:5])
```


```{r}
# Clean the Corpus

# Remove punctuation
corpus <- tm_map(corpus, content_transformer(removePunctuation))
# Send everything to lower case
corpus <- tm_map(corpus, content_transformer(tolower))
# Remove stopwords
corpus <- tm_map(corpus, content_transformer(removeWords), 
          stopwords("english"))
# Remove whitespace
corpus <- tm_map(corpus, stripWhitespace)
# Remove numbers
corpus <- tm_map(corpus, content_transformer(removeNumbers))
# Stemming
corpus <- tm_map(corpus, stemDocument)

inspect(corpus[1:5])
```

```{r}
# Create DTM object
dtm <- DocumentTermMatrix(corpus)
# Weight TF-IDF
tfidf_dtm <- weightTfIdf(dtm)
inspect(tfidf_dtm[,1:3])
```


```{r}
tfidf_mat <- as.matrix(tfidf_dtm)

tfidf_vec <- as.vector(tfidf_mat)

tfidf_vec <- tfidf_vec[tfidf_vec > 0] 

quants <- quantile(tfidf_vec, probs = seq(0.8,0.9,0.05))
quants
```

do weighting stuff
```{r}

```


```{r}
 # Filter DTM
  tfidf_dtm_r <- tfidf_dtm[,tfidf_dtm$v > 1.2529668]

  # Construct dataframe for fitting
  x_data <- as.data.frame(as.matrix(tfidf_dtm_r))
  # data <- cbind(y,data)
  # y_data <- as.data.frame(subset(full_data, doc_id %in% tfidf_dtm_r$dimnames$Docs))$Sarcastic
  data <- cbind(y,x_data)
  # colnames(data)[1] <- "y"
  weights <- c()
  w1 = 0.01
  w2 = 1 - w1
  
  for (i in 1:nrow(data)) {
    if(data[i,1]==1){
      weights <- c(weights,w1)
    }else{
      weights <- c(weights,w2)
    }
  }
  
set.seed(87460945)
train_idx <- sample(1:nrow(data),floor(.6*(nrow(data))))
test_idx <- setdiff(1:nrow(data),train_idx)
  
glm.out <- glm(y~., family = binomial, data[train_idx,])
# summary(glm.out)
```

```{r Split data intro train/test}
predict.out <- predict(glm.out, newdata = as.data.frame(as.matrix(tfidf_dtm[test_idx,])) ,type="response")

predict.out[which(predict.out >= 0.5)] <- 1

predict.out[which(predict.out < 0.5)] <- 0

guess <- data.frame(predict.out)

output <- cbind(guess,y[test_idx])
colnames(output)[2] <- "truth"
output
```



```{r}
library(MLmetrics)
cm <- ConfusionMatrix(output$predict.out, output$truth)
print(cm)

y_true <- output$truth
y_pred <- output$predict.out
print("Specificity:")
Specificity(y_true, y_pred, positive = 1)

print("Recall:")
Recall(y_true, y_pred, positive = 1)

print("Precision:")
Precision(y_true, y_pred, positive = 1)

print("Accuracy:")
Accuracy(y_pred, y_true)

print("F1_Score:")
F1_Score(y_true, y_pred, positive = 1)
```




























# LASSO
**TODO: explore LASSSO**

```{r}
glmnet.out <- glmnet(tfidf_dtm, y_1to2, family = "binomial")
plot(glmnet.out)
```

